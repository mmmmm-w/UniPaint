{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from einops import rearrange\n",
    "\n",
    "from transformers import CLIPTextModel, CLIPTokenizer\n",
    "from diffusers import AutoencoderKL, DDIMScheduler\n",
    "\n",
    "from unipaint.pipelines.pipeline_unipaint import AnimationPipeline\n",
    "from unipaint.models.unet import UNet3DConditionModel\n",
    "from unipaint.models.sparse_controlnet import SparseControlNetModel\n",
    "from unipaint.models.unipaint.brushnet import BrushNetModel\n",
    "\n",
    "from unipaint.utils.util import load_weights,save_videos_grid\n",
    "import decord\n",
    "decord.bridge.set_bridge(\"torch\")\n",
    "from unipaint.utils.mask import StaticRectangularMaskGenerator\n",
    "\n",
    "data = \"Running4\"\n",
    "path = \"models/StableDiffusion/stable-diffusion-v1-5\"\n",
    "brushnet_path = \"models/BrushNet/random_mask_brushnet_ckpt\"\n",
    "device = \"cuda:4\"\n",
    "dtype = torch.float16\n",
    "\n",
    "use_motion_module = True\n",
    "use_adapter = True\n",
    "\n",
    "motion_module_path = \"models/Motion_Module/v3_sd15_mm.ckpt\" if use_motion_module else \"\"\n",
    "adapter_path = \"models/Motion_Module/v3_sd15_adapter.ckpt\" if use_adapter else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 3D unet's pretrained weights from models/StableDiffusion/stable-diffusion-v1-5 ...\n",
      "### missing keys: 520; \n",
      "### unexpected keys: 0;\n",
      "### Motion Module Parameters: 417.1376 M\n"
     ]
    }
   ],
   "source": [
    "#load base model\n",
    "tokenizer        = CLIPTokenizer.from_pretrained(path, subfolder=\"tokenizer\", torch_dtype=dtype)\n",
    "text_encoder     = CLIPTextModel.from_pretrained(path, subfolder=\"text_encoder\").to(device,dtype)\n",
    "vae              = AutoencoderKL.from_pretrained(path, subfolder=\"vae\").to(device, dtype)\n",
    "\n",
    "inference_config = OmegaConf.load(\"configs/inference/inference-v3.yaml\")\n",
    "unet             = UNet3DConditionModel.from_pretrained_2d(path, subfolder=\"unet\", unet_additional_kwargs=OmegaConf.to_container(inference_config.unet_additional_kwargs)).to(device, dtype)\n",
    "\n",
    "#load controlnet\n",
    "unet.config.num_attention_heads = 8\n",
    "unet.config.projection_class_embeddings_input_dim = None\n",
    "controlnet_config = OmegaConf.load(\"configs/inference/sparsectrl/latent_condition.yaml\")\n",
    "controlnet = SparseControlNetModel.from_unet(unet, controlnet_additional_kwargs=controlnet_config.get(\"controlnet_additional_kwargs\", {}))\n",
    "controlnet_state_dict = torch.load(\"models/Motion_Module/v3_sd15_sparsectrl_rgb.ckpt\", map_location=\"cpu\")\n",
    "controlnet_state_dict = controlnet_state_dict[\"controlnet\"] if \"controlnet\" in controlnet_state_dict else controlnet_state_dict\n",
    "controlnet_state_dict = {name: param for name, param in controlnet_state_dict.items() if \"pos_encoder.pe\" not in name}\n",
    "controlnet_state_dict.pop(\"animatediff_config\", \"\")\n",
    "controlnet.load_state_dict(controlnet_state_dict)\n",
    "controlnet.to(device, dtype)\n",
    "\n",
    "#load brushnet\n",
    "brushnet = BrushNetModel.from_pretrained(brushnet_path, torch_dtype=dtype).to(device)\n",
    "\n",
    "#build pipeline\n",
    "pipeline = AnimationPipeline(\n",
    "            vae=vae, text_encoder=text_encoder, tokenizer=tokenizer, unet=unet,\n",
    "            controlnet=controlnet, brushnet = brushnet,\n",
    "            scheduler=DDIMScheduler(beta_start=0.00085,\n",
    "                                                beta_end=0.012,\n",
    "                                                beta_schedule=\"linear\",\n",
    "                                                steps_offset=0,\n",
    "                                                clip_sample=False)\n",
    "                                                ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load motion module from models/Motion_Module/v3_sd15_mm.ckpt\n",
      "load domain lora from models/Motion_Module/v3_sd15_adapter.ckpt\n"
     ]
    }
   ],
   "source": [
    "pipeline = load_weights(\n",
    "    pipeline,\n",
    "    # motion module\n",
    "    motion_module_path         = motion_module_path,\n",
    "    motion_module_lora_configs = [],\n",
    "    # domain adapter\n",
    "    adapter_lora_path          = adapter_path,\n",
    "    adapter_lora_scale         = 1.0,\n",
    "    # image layers\n",
    "    dreambooth_model_path      = \"\",\n",
    "    lora_model_path            = \"\",\n",
    "    lora_alpha                 = 0.8,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Video\n",
    "Here we read frames of a video and generate a corresponding mask. The data is normalized to [0, 1], in shape (b f) c h w."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = f\"outpaint_videos/SB_{data}.mp4\"\n",
    "vr = decord.VideoReader(video_path, width=512, height=512)\n",
    "\n",
    "video = vr.get_batch(list(range(0,16)))\n",
    "video = rearrange(video, \"f h w c -> c f h w\")\n",
    "frame = torch.clone(torch.unsqueeze(video/255, dim=0)).to(device, brushnet.dtype)\n",
    "del(vr)\n",
    "mask_generator = StaticRectangularMaskGenerator(mask_l=[0,0.4],\n",
    "                                          mask_r=[0,0.4],\n",
    "                                          mask_t=[0,0.4],\n",
    "                                          mask_b=[0,0.4])\n",
    "mask = mask_generator(frame)\n",
    "frame[mask==1]=0\n",
    "mask = mask.to(device, brushnet.dtype)\n",
    "frame = frame*2.-1.\n",
    "mask = mask*2.-1.\n",
    "\n",
    "save_videos_grid(((frame+1)/2).cpu(), f\"samples/{data}/masked_video.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:34<00:00,  1.38s/it]\n",
      "100%|██████████| 16/16 [00:01<00:00, 13.69it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 95.11 GiB of which 88.25 MiB is free. Process 381632 has 320.00 MiB memory in use. Process 381635 has 320.00 MiB memory in use. Process 381630 has 320.00 MiB memory in use. Process 381628 has 64.61 GiB memory in use. Process 381634 has 320.00 MiB memory in use. Process 381629 has 320.00 MiB memory in use. Process 381633 has 320.00 MiB memory in use. Process 381631 has 320.00 MiB memory in use. Process 3075899 has 28.17 GiB memory in use. Of the allocated memory 27.26 GiB is allocated by PyTorch, and 411.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m num_controlnet_images \u001b[38;5;241m=\u001b[39m controlnet_images\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     26\u001b[0m controlnet_images \u001b[38;5;241m=\u001b[39m rearrange(controlnet_images, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb c f h w -> (b f) c h w\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m controlnet_images \u001b[38;5;241m=\u001b[39m \u001b[43mvae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontrolnet_images\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlatent_dist\u001b[38;5;241m.\u001b[39msample() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.18215\u001b[39m\n\u001b[1;32m     28\u001b[0m controlnet_images \u001b[38;5;241m=\u001b[39m rearrange(controlnet_images, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(b f) c h w -> b c f h w\u001b[39m\u001b[38;5;124m\"\u001b[39m, f\u001b[38;5;241m=\u001b[39mnum_controlnet_images)\n\u001b[1;32m     30\u001b[0m sample \u001b[38;5;241m=\u001b[39m pipeline(\n\u001b[1;32m     31\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m prompt,\n\u001b[1;32m     32\u001b[0m     negative_prompt     \u001b[38;5;241m=\u001b[39m n_prompt,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m     controlnet_conditioning_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m     42\u001b[0m )\u001b[38;5;241m.\u001b[39mvideos\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tuna/lib/python3.10/site-packages/diffusers/models/vae.py:566\u001b[0m, in \u001b[0;36mAutoencoderKL.encode\u001b[0;34m(self, x, return_dict)\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mFloatTensor, return_dict: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AutoencoderKLOutput:\n\u001b[0;32m--> 566\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m     moments \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquant_conv(h)\n\u001b[1;32m    568\u001b[0m     posterior \u001b[38;5;241m=\u001b[39m DiagonalGaussianDistribution(moments)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tuna/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tuna/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tuna/lib/python3.10/site-packages/diffusers/models/vae.py:134\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# down\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m down_block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_blocks:\n\u001b[0;32m--> 134\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[43mdown_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# middle\u001b[39;00m\n\u001b[1;32m    137\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmid_block(sample)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tuna/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tuna/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tuna/lib/python3.10/site-packages/diffusers/models/unet_2d_blocks.py:920\u001b[0m, in \u001b[0;36mDownEncoderBlock2D.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m resnet \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresnets:\n\u001b[0;32m--> 920\u001b[0m         hidden_states \u001b[38;5;241m=\u001b[39m \u001b[43mresnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    922\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsamplers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    923\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m downsampler \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsamplers:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tuna/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tuna/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tuna/lib/python3.10/site-packages/diffusers/models/resnet.py:493\u001b[0m, in \u001b[0;36mResnetBlock2D.forward\u001b[0;34m(self, input_tensor, temb)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_shortcut \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    491\u001b[0m     input_tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_shortcut(input_tensor)\n\u001b[0;32m--> 493\u001b[0m output_tensor \u001b[38;5;241m=\u001b[39m (\u001b[43minput_tensor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mhidden_states\u001b[49m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_scale_factor\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output_tensor\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 95.11 GiB of which 88.25 MiB is free. Process 381632 has 320.00 MiB memory in use. Process 381635 has 320.00 MiB memory in use. Process 381630 has 320.00 MiB memory in use. Process 381628 has 64.61 GiB memory in use. Process 381634 has 320.00 MiB memory in use. Process 381629 has 320.00 MiB memory in use. Process 381633 has 320.00 MiB memory in use. Process 381631 has 320.00 MiB memory in use. Process 3075899 has 28.17 GiB memory in use. Of the allocated memory 27.26 GiB is allocated by PyTorch, and 411.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "prompt = \"a man in blue, running\"\n",
    "n_prompt = \"worst quality, low quality, letterboxed\"\n",
    "sample = pipeline(\n",
    "    prompt = prompt,\n",
    "    negative_prompt     = n_prompt,\n",
    "    num_inference_steps = 25,\n",
    "    guidance_scale      = 12.5,\n",
    "    width               = 512,\n",
    "    height              = 512,\n",
    "    video_length        = 16,\n",
    "\n",
    "    controlnet_images = None,\n",
    "    controlnet_image_index = [0],\n",
    "    controlnet_conditioning_scale=0.0,\n",
    "\n",
    "    init_video = frame[:,:,:],\n",
    "    mask_video = mask[:,:,:],\n",
    "    brushnet_conditioning_scale = 1.0,\n",
    "    control_guidance_start = 0.0,\n",
    "    control_guidance_end = 1.0,\n",
    "    ).videos\n",
    "save_videos_grid(sample, f\"samples/{data}/brushnet_mm_{use_motion_module}_adapter_{use_adapter}.gif\")\n",
    "\n",
    "controlnet_images = torch.clone(frame)\n",
    "num_controlnet_images = controlnet_images.shape[2]\n",
    "controlnet_images = rearrange(controlnet_images, \"b c f h w -> (b f) c h w\")\n",
    "controlnet_images = vae.encode(controlnet_images).latent_dist.sample() * 0.18215\n",
    "controlnet_images = rearrange(controlnet_images, \"(b f) c h w -> b c f h w\", f=num_controlnet_images)\n",
    "\n",
    "sample = pipeline(\n",
    "    prompt = prompt,\n",
    "    negative_prompt     = n_prompt,\n",
    "    num_inference_steps = 25,\n",
    "    guidance_scale      = 12.5,\n",
    "    width               = 512,\n",
    "    height              = 512,\n",
    "    video_length        = 16,\n",
    "\n",
    "    controlnet_images = controlnet_images,\n",
    "    controlnet_image_index = [0],\n",
    "    controlnet_conditioning_scale=1.0\n",
    ").videos\n",
    "save_videos_grid(sample, f\"samples/{data}/controlnet_mm_{use_motion_module}_adapter_{use_adapter}.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible trainings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Trainable params: options\n",
    "    1. Motion Lora\n",
    "    2. Temporal layers in Brushnet (How?)\n",
    "    3. Whole motion module\n",
    "2. Data\n",
    "    1. WebVid or similar video datasets\n",
    "    2. Maybe some video segmentation dataset? These dataset should provide masks and corresponding tags\n",
    "3. How to train\n",
    "    - I have no experience of training a large model from scratch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from unipaint.data.dataset import WebVid10M\n",
    "import decord\n",
    "decord.bridge.set_bridge(\"torch\")\n",
    "dataset = WebVid10M(\n",
    "        csv_path=\"data/webvid-10M/data/train/partitions/0000.csv\",\n",
    "        video_folder=\"/mnt/data/user/fan_xiaoran/data/videos/webvid-10M/videos\",\n",
    "        sample_size=256,\n",
    "        sample_stride=4, \n",
    "        sample_n_frames=16\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dataset.__getitem__(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixel_values = sample[\"pixel_values\"]\n",
    "pixel_values.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Airplane landing chepstow'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_values = rearrange(pixel_values, \"f c h w -> c f h w\")\n",
    "frame = torch.clone(torch.unsqueeze(pixel_values, dim=0)).to(device)\n",
    "mask_generator = RectangularMaskGenerator(mask_l=[0,0.4],\n",
    "                                          mask_r=[0,0.4],\n",
    "                                          mask_t=[0,0.4],\n",
    "                                          mask_b=[0,0.4])\n",
    "mask = mask_generator(frame)\n",
    "frame[mask==1]=0\n",
    "mask = mask.to(device)\n",
    "frame = frame*2.-1.\n",
    "mask = mask*2.-1.\n",
    "\n",
    "save_videos_grid(((frame+1)/2).cpu(), f\"./test_masked_video.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212,\n",
       "        212, 212,  41,  41,  41,  41,  41,  41,  41,  41,  41,  41,  41,  41,\n",
       "         41,  41,  41,  41, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213,\n",
       "        213, 213, 213, 213, 213, 213,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "          2,   2,   2,   2,   2,   2,   2,   2])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timesteps = torch.tensor([212,41,213,2]).unsqueeze(dim=1)\n",
    "timesteps = torch.cat([timesteps]*16,dim=1).flatten()\n",
    "timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tuna/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 3D unet's pretrained weights from models/StableDiffusion/stable-diffusion-v1-5 ...\n",
      "### missing keys: 520; \n",
      "### unexpected keys: 0;\n",
      "### Motion Module Parameters: 417.1376 M\n",
      "load motion module from models/Motion_Module/v3_sd15_mm.ckpt\n",
      "load domain lora from models/Motion_Module/v3_sd15_adapter.ckpt\n",
      "global_step: 13000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from einops import rearrange\n",
    "\n",
    "from transformers import CLIPTextModel, CLIPTokenizer\n",
    "from diffusers import AutoencoderKL, DDIMScheduler\n",
    "\n",
    "from unipaint.pipelines.pipeline_unipaint import AnimationPipeline\n",
    "from unipaint.models.unet import UNet3DConditionModel\n",
    "from unipaint.models.sparse_controlnet import SparseControlNetModel\n",
    "from unipaint.models.unipaint.brushnet import BrushNetModel\n",
    "\n",
    "from unipaint.utils.util import load_weights,save_videos_grid\n",
    "import decord\n",
    "decord.bridge.set_bridge(\"torch\")\n",
    "from unipaint.utils.mask import RectangularMaskGenerator\n",
    "path = \"models/StableDiffusion/stable-diffusion-v1-5\"\n",
    "brushnet_path = \"models/BrushNet/random_mask_brushnet_ckpt\"\n",
    "device = \"cuda:4\"\n",
    "dtype = torch.float16\n",
    "\n",
    "use_motion_module = True\n",
    "use_adapter = True\n",
    "\n",
    "motion_module_path = \"models/Motion_Module/v3_sd15_mm.ckpt\" if use_motion_module else \"\"\n",
    "adapter_path = \"models/Motion_Module/v3_sd15_adapter.ckpt\" if use_adapter else \"\"\n",
    "\n",
    "#load base model\n",
    "tokenizer        = CLIPTokenizer.from_pretrained(path, subfolder=\"tokenizer\", torch_dtype=dtype)\n",
    "text_encoder     = CLIPTextModel.from_pretrained(path, subfolder=\"text_encoder\").to(device,dtype)\n",
    "vae              = AutoencoderKL.from_pretrained(path, subfolder=\"vae\").to(device, dtype)\n",
    "\n",
    "inference_config = OmegaConf.load(\"configs/inference/inference-v3.yaml\")\n",
    "unet             = UNet3DConditionModel.from_pretrained_2d(path, subfolder=\"unet\", unet_additional_kwargs=OmegaConf.to_container(inference_config.unet_additional_kwargs)).to(device, dtype)\n",
    "\n",
    "#load brushnet\n",
    "brushnet = BrushNetModel.from_pretrained(brushnet_path, torch_dtype=dtype).to(device)\n",
    "\n",
    "#build pipeline\n",
    "pipeline = AnimationPipeline(\n",
    "            vae=vae, text_encoder=text_encoder, tokenizer=tokenizer, unet=unet,\n",
    "            brushnet = brushnet,\n",
    "            scheduler=DDIMScheduler(beta_start=0.00085,\n",
    "                                                beta_end=0.012,\n",
    "                                                beta_schedule=\"linear\",\n",
    "                                                steps_offset=0,\n",
    "                                                clip_sample=False)\n",
    "                                                ).to(device)\n",
    "\n",
    "pipeline = load_weights(\n",
    "    pipeline,\n",
    "    # motion module\n",
    "    motion_module_path         = motion_module_path,\n",
    "    motion_module_lora_configs = [],\n",
    "    # domain adapter\n",
    "    adapter_lora_path          = adapter_path,\n",
    "    adapter_lora_scale         = 1.0,\n",
    "    # image layers\n",
    "    dreambooth_model_path      = \"\",\n",
    "    lora_model_path            = \"\",\n",
    "    lora_alpha                 = 0.8,\n",
    ").to(device)\n",
    "\n",
    "unet_checkpoint_path = \"outputs/unipaint_training_mask-2024-09-03T18-40-37/checkpoints/checkpoint.ckpt\"\n",
    "unet_checkpoint_path = torch.load(unet_checkpoint_path, map_location=\"cpu\")\n",
    "if \"global_step\" in unet_checkpoint_path: print(f\"global_step: {unet_checkpoint_path['global_step']}\")\n",
    "state_dict = unet_checkpoint_path[\"state_dict\"] if \"state_dict\" in unet_checkpoint_path else unet_checkpoint_path\n",
    "new_state_dict = {}\n",
    "for k, v in state_dict.items():\n",
    "    new_key = k.replace('module.', '')  # Remove 'module.' from each key\n",
    "    new_state_dict[new_key] = v\n",
    "\n",
    "m, u = unet.load_state_dict(new_state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:19<00:00,  1.27it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 27.34it/s]\n",
      "100%|██████████| 25/25 [00:19<00:00,  1.27it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 27.36it/s]\n",
      "100%|██████████| 25/25 [00:19<00:00,  1.27it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 27.35it/s]\n",
      "100%|██████████| 25/25 [00:19<00:00,  1.27it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 27.35it/s]\n",
      "100%|██████████| 25/25 [00:19<00:00,  1.27it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 27.32it/s]\n",
      "100%|██████████| 25/25 [00:19<00:00,  1.27it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 27.35it/s]\n",
      "100%|██████████| 25/25 [00:19<00:00,  1.27it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 27.34it/s]\n",
      "100%|██████████| 25/25 [00:19<00:00,  1.27it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 27.34it/s]\n",
      "100%|██████████| 25/25 [00:19<00:00,  1.27it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 27.36it/s]\n",
      "100%|██████████| 25/25 [00:19<00:00,  1.27it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 27.28it/s]\n",
      "100%|██████████| 25/25 [00:19<00:00,  1.27it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 27.37it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "name = \"chicken\"\n",
    "if name == \"eagle\":\n",
    "    video_path = f\"outpaint_videos/SB_Eagle.mp4\"\n",
    "    prompt = \"a white head bald eagle\"\n",
    "    n_prompt = \"\"\n",
    "    data = np.load('SB_Eagle_mask.npz')\n",
    "if name == \"chicken\":\n",
    "    video_path = f\"outpaint_videos/SB_Eagle.mp4\"\n",
    "    prompt = \"a chicke\"\n",
    "    n_prompt = \"\"\n",
    "    data = np.load('SB_Eagle_mask.npz')\n",
    "if name == \"dog\":\n",
    "    video_path = f\"outpaint_videos/SB_Dog1.mp4\"\n",
    "    prompt = \"a white fluffy dog walking\"\n",
    "    n_prompt = \"\"\n",
    "    data = np.load('SB_Dog1_mask.npz')\n",
    "\n",
    "vr = decord.VideoReader(video_path, width=512, height=512)\n",
    "\n",
    "video = vr.get_batch(list(range(0,16)))\n",
    "video = rearrange(video, \"f h w c -> c f h w\")\n",
    "frame = torch.clone(torch.unsqueeze(video/255, dim=0)).to(device, brushnet.dtype)\n",
    "del(vr)\n",
    "\n",
    "mask = torch.tensor(np.unpackbits(data['mask']).reshape((16, 512, 512)))\n",
    "mask = torch.cat([mask.unsqueeze(dim=0)]*3,dim=0).unsqueeze(dim=0)\n",
    "frame[mask==1]=0\n",
    "mask = mask.to(device, brushnet.dtype)\n",
    "frame = frame*2.-1.\n",
    "mask = mask*2.-1.\n",
    "save_videos_grid(((frame+1)/2).cpu(), f\"./test_masked_video_{name}.gif\")\n",
    "samples = []\n",
    "samples.append(((frame+1)/2).cpu())\n",
    "for scale in np.arange(0.0, 1.1, 0.1).tolist():\n",
    "    sample = pipeline(\n",
    "        prompt = prompt,\n",
    "        negative_prompt     = n_prompt,\n",
    "        num_inference_steps = 25,\n",
    "        guidance_scale      = 12.5,\n",
    "        width               = 512,\n",
    "        height              = 512,\n",
    "        video_length        = 16,\n",
    "\n",
    "        init_video = frame[:,:,:],\n",
    "        mask_video = mask[:,:,:],\n",
    "        brushnet_conditioning_scale = scale,\n",
    "        control_guidance_start = 0.0,\n",
    "        control_guidance_end = 1.0,\n",
    "        ).videos\n",
    "    samples.append(sample)\n",
    "samples = torch.concat(samples)\n",
    "save_videos_grid(samples, f\"./sam_test_{name}.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tuna/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " video num:  3471  clip num:  29631\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from unipaint.data.ytvos import YTVOSDataset\n",
    "import torch\n",
    "img_folder = \"./data/YoutubeVOS/train\"\n",
    "ann_file = \"./data/YoutubeVOS/meta_expressions/train/meta_expressions.json\"\n",
    "image_set = \"train\"\n",
    "\n",
    "dataset = YTVOSDataset(img_folder, ann_file, sample_size=256, return_masks=True, \n",
    "                           num_frames=16)                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dataset.__getitem__(634)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a monkey climbing down from the top of the tree while another is below'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 256, 256])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[\"masks\"].to(torch.float32).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(sample[\"masks\"].to(torch.float32)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "         [[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "         [[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]]],\n",
       "\n",
       "\n",
       "        [[[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "         [[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "         [[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]]],\n",
       "\n",
       "\n",
       "        [[[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "         [[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "         [[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "         [[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "         [[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]]],\n",
       "\n",
       "\n",
       "        [[[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "         [[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "         [[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]]],\n",
       "\n",
       "\n",
       "        [[[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "         [[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "         [[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[\"masks\"].to(torch.float32)==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class MovingRectangularMaskGenerator:\n",
    "    def __init__(self, rect_height_range, rect_width_range) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the MovingRectangularMaskGenerator with random rectangle sizes and movement.\n",
    "\n",
    "        Args:\n",
    "        - rect_height_range (tuple): A tuple (min_height, max_height) defining the range for the height of the rectangle.\n",
    "        - rect_width_range (tuple): A tuple (min_width, max_width) defining the range for the width of the rectangle.\n",
    "        \"\"\"\n",
    "        self.rect_height_range = rect_height_range\n",
    "        self.rect_width_range = rect_width_range\n",
    "\n",
    "    def __call__(self, control):\n",
    "        \"\"\"\n",
    "        Generate a moving rectangular mask with random size and random movement.\n",
    "\n",
    "        Args:\n",
    "        - control (torch.Tensor): The control tensor to apply the mask to.\n",
    "                                  Expected shape: (batch, num_frames, channels, height, width)\n",
    "\n",
    "        Returns:\n",
    "        - mask (torch.Tensor): The generated moving rectangular mask tensor.\n",
    "                               Shape: (batch, num_frames, channels, height, width)\n",
    "        \"\"\"\n",
    "        # Control tensor dimensions\n",
    "        batch_size = control.shape[0]\n",
    "        num_frames = control.shape[1]\n",
    "        h = control.shape[-2]\n",
    "        w = control.shape[-1]\n",
    "\n",
    "        # Initialize a mask of ones (fully transparent to begin with)\n",
    "        mask = torch.zeros_like(control)\n",
    "\n",
    "        # Randomly choose rectangle sizes (height and width) for each sample in the batch\n",
    "        rect_heights = torch.randint(self.rect_height_range[0], self.rect_height_range[1], (batch_size,))\n",
    "        rect_widths = torch.randint(self.rect_width_range[0], self.rect_width_range[1], (batch_size,))\n",
    "\n",
    "        # For each batch element, ensure valid starting and ending positions\n",
    "        x_start = torch.zeros(batch_size, dtype=torch.long)\n",
    "        y_start = torch.zeros(batch_size, dtype=torch.long)\n",
    "        x_end = torch.zeros(batch_size, dtype=torch.long)\n",
    "        y_end = torch.zeros(batch_size, dtype=torch.long)\n",
    "\n",
    "        for batch_idx in range(batch_size):\n",
    "            rect_height = rect_heights[batch_idx]\n",
    "            rect_width = rect_widths[batch_idx]\n",
    "\n",
    "            # Ensure the starting point is valid\n",
    "            x_start[batch_idx] = torch.randint(0, w - rect_width + 1, (1,))\n",
    "            y_start[batch_idx] = torch.randint(0, h - rect_height + 1, (1,))\n",
    "\n",
    "            # Ensure the ending point is valid\n",
    "            x_end[batch_idx] = torch.randint(0, w - rect_width + 1, (1,))\n",
    "            y_end[batch_idx] = torch.randint(0, h - rect_height + 1, (1,))\n",
    "\n",
    "        # For each batch element, generate linear interpolation of positions over frames\n",
    "        for batch_idx in range(batch_size):\n",
    "            rect_height = rect_heights[batch_idx]\n",
    "            rect_width = rect_widths[batch_idx]\n",
    "\n",
    "            # Interpolate the x and y positions for all frames\n",
    "            x_positions = torch.linspace(x_start[batch_idx], x_end[batch_idx], num_frames).long()\n",
    "            y_positions = torch.linspace(y_start[batch_idx], y_end[batch_idx], num_frames).long()\n",
    "\n",
    "            # Apply the moving rectangle to each frame\n",
    "            for frame_idx in range(num_frames):\n",
    "                x_st = x_positions[frame_idx]\n",
    "                y_st = y_positions[frame_idx]\n",
    "                x_end_frame = min(x_st + rect_width, w)\n",
    "                y_end_frame = min(y_st + rect_height, h)\n",
    "\n",
    "                # Apply the mask by zeroing out the pixels inside the rectangle\n",
    "                mask[batch_idx, frame_idx, :, y_st:y_end_frame, x_st:x_end_frame] = 1.0\n",
    "\n",
    "        return mask\n",
    "# Example usage\n",
    "batch_size = 2\n",
    "num_frames = 16\n",
    "height, width = 256, 256\n",
    "\n",
    "# Simulated control tensor (e.g., batch of videos)\n",
    "control_tensor = torch.randn((batch_size, num_frames, 3, height, width))\n",
    "\n",
    "# Instantiate the moving rectangular mask generator with random size and movement\n",
    "mask_generator = MovingRectangularMaskGenerator(\n",
    "    rect_height_range=(30, 100),  # Random height between 5 and 20 pixels\n",
    "    rect_width_range=(30, 100),   # Random width between 5 and 20 pixels\n",
    ")\n",
    "\n",
    "# Generate the mask\n",
    "mask = mask_generator(control_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unipaint.utils.util import save_videos_grid\n",
    "save_videos_grid(mask.permute(0,2,1,3,4).to(torch.float), \"./mask.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 16, 3, 256, 256])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 16, 3, 256, 256])\n",
      "torch.Size([2, 16, 3, 256, 256])\n",
      "torch.Size([2, 16, 3, 256, 256])\n",
      "torch.Size([2, 16, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "from unipaint.utils.mask import StaticRectangularMaskGenerator, MovingRectangularMaskGenerator, MarginalMaskGenerator, InterpolationMaskGenerator\n",
    "import torch\n",
    "mask_generators = [\n",
    "    StaticRectangularMaskGenerator(mask_l=[0,0.4],\n",
    "                                    mask_r=[0,0.4],\n",
    "                                    mask_t=[0,0.4],\n",
    "                                    mask_b=[0,0.4]),  # Example generator with fixed sizes\n",
    "    MovingRectangularMaskGenerator(rect_height_range=(30, 100), rect_width_range=(30, 100)),  # Random size\n",
    "    MarginalMaskGenerator(mask_l=[0,0.4],\n",
    "                        mask_r=[0,0.4],\n",
    "                        mask_t=[0,0.4],\n",
    "                        mask_b=[0,0.4]),  # Random margin width\n",
    "    InterpolationMaskGenerator(stride_range=(2, 5))  # Random stride\n",
    "]\n",
    "# Example usage\n",
    "batch_size = 2\n",
    "num_frames = 16\n",
    "height, width = 256, 256\n",
    "\n",
    "# Simulated control tensor (e.g., batch of videos)\n",
    "control_tensor = torch.randn((batch_size, num_frames, 3, height, width))\n",
    "\n",
    "for generator in mask_generators:\n",
    "    mask = generator(control_tensor)\n",
    "    print(mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = f\"outpaint_videos/SB_{data}.mp4\"\n",
    "vr = decord.VideoReader(video_path, width=512, height=512)\n",
    "\n",
    "video = vr.get_batch(list(range(0,16)))\n",
    "video = rearrange(video, \"f h w c -> c f h w\")\n",
    "frame = torch.clone(torch.unsqueeze(video/255, dim=0)).to(device, brushnet.dtype)\n",
    "del(vr)\n",
    "mask_generator = MovingRectangularMaskGenerator(rect_height_range=(30, 100), rect_width_range=(30, 100)) # Random margin width\n",
    "mask = mask_generator(frame)\n",
    "frame[mask==1]=0\n",
    "mask = mask.to(device, brushnet.dtype)\n",
    "frame = frame*2.-1.\n",
    "mask = mask*2.-1.\n",
    "\n",
    "save_videos_grid(((frame+1)/2).cpu(), f\"samples/{data}/masked_video.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovingRectangularMaskGenerator:\n",
    "    def __init__(self, rect_height_range, rect_width_range) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the MovingRectangularMaskGenerator with random rectangle sizes and movement.\n",
    "\n",
    "        Args:\n",
    "        - rect_height_range (tuple): A tuple (min_height, max_height) defining the range for the height of the rectangle.\n",
    "        - rect_width_range (tuple): A tuple (min_width, max_width) defining the range for the width of the rectangle.\n",
    "        \"\"\"\n",
    "        self.rect_height_range = rect_height_range\n",
    "        self.rect_width_range = rect_width_range\n",
    "\n",
    "    def __call__(self, control):\n",
    "        \"\"\"\n",
    "        Generate a moving rectangular mask with random size and random movement.\n",
    "\n",
    "        Args:\n",
    "        - control (torch.Tensor): The control tensor to apply the mask to.\n",
    "                                  Expected shape: (batch, num_frames, channels, height, width)\n",
    "\n",
    "        Returns:\n",
    "        - mask (torch.Tensor): The generated moving rectangular mask tensor.\n",
    "                               Shape: (batch, num_frames, channels, height, width)\n",
    "        \"\"\"\n",
    "        # Control tensor dimensions\n",
    "        batch_size = control.shape[0]\n",
    "        num_frames = control.shape[2]\n",
    "        h = control.shape[-2]\n",
    "        w = control.shape[-1]\n",
    "\n",
    "        # Initialize a mask of ones (fully transparent to begin with)\n",
    "        mask = torch.zeros_like(control)\n",
    "\n",
    "        # Randomly choose rectangle sizes (height and width) for each sample in the batch\n",
    "        rect_heights = torch.randint(self.rect_height_range[0], self.rect_height_range[1], (batch_size,))\n",
    "        rect_widths = torch.randint(self.rect_width_range[0], self.rect_width_range[1], (batch_size,))\n",
    "\n",
    "        # For each batch element, ensure valid starting and ending positions\n",
    "        x_start = torch.zeros(batch_size, dtype=torch.long)\n",
    "        y_start = torch.zeros(batch_size, dtype=torch.long)\n",
    "        x_end = torch.zeros(batch_size, dtype=torch.long)\n",
    "        y_end = torch.zeros(batch_size, dtype=torch.long)\n",
    "\n",
    "        for batch_idx in range(batch_size):\n",
    "            rect_height = rect_heights[batch_idx]\n",
    "            rect_width = rect_widths[batch_idx]\n",
    "\n",
    "            # Ensure the starting point is valid\n",
    "            x_start[batch_idx] = torch.randint(0, w - rect_width + 1, (1,))\n",
    "            y_start[batch_idx] = torch.randint(0, h - rect_height + 1, (1,))\n",
    "\n",
    "            # Ensure the ending point is valid\n",
    "            x_end[batch_idx] = torch.randint(0, w - rect_width + 1, (1,))\n",
    "            y_end[batch_idx] = torch.randint(0, h - rect_height + 1, (1,))\n",
    "\n",
    "        # For each batch element, generate linear interpolation of positions over frames\n",
    "        for batch_idx in range(batch_size):\n",
    "            rect_height = rect_heights[batch_idx]\n",
    "            rect_width = rect_widths[batch_idx]\n",
    "\n",
    "            # Interpolate the x and y positions for all frames\n",
    "            x_positions = torch.linspace(x_start[batch_idx], x_end[batch_idx], num_frames).long()\n",
    "            y_positions = torch.linspace(y_start[batch_idx], y_end[batch_idx], num_frames).long()\n",
    "\n",
    "            # Apply the moving rectangle to each frame\n",
    "            for frame_idx in range(num_frames):\n",
    "                x_st = x_positions[frame_idx]\n",
    "                y_st = y_positions[frame_idx]\n",
    "                x_end_frame = min(x_st + rect_width, w)\n",
    "                y_end_frame = min(y_st + rect_height, h)\n",
    "\n",
    "                # Apply the mask by zeroing out the pixels inside the rectangle\n",
    "                mask[batch_idx, :, frame_idx, y_st:y_end_frame, x_st:x_end_frame] = 1.0\n",
    "\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tuna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
